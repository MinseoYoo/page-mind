"""
Gradio ì›¹ ë°ëª¨ - ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ + ë„ì„œ ì¶”ì²œ
ë‹¨ì¼ íƒ­ êµ¬ì„±, 5íšŒ ì´ìƒ ëŒ€í™” ì‹œ ìë™ ë¶„ì„ ë° ì¶”ì²œ
"""

import sys
import platform
import asyncio

# Windowsì—ì„œ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì •ì±… ì„¤ì • (Gradio ì‹œì‘ ì „ì—)
if platform.system() == 'Windows':
    if sys.version_info >= (3, 8):
        # Windowsì—ì„œ SelectorEventLoop ì‚¬ìš© (ProactorEventLoop ëŒ€ì‹ )
        # ProactorEventLoopëŠ” socket.socketpair()ì—ì„œ ë¬¸ì œ ë°œìƒ
        try:
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        except AttributeError:
            # Python 3.7 ì´í•˜ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€
            pass

import gradio as gr
from datetime import datetime
from typing import List, Tuple
import json
import os

from dotenv import load_dotenv
load_dotenv()
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# CrewAI Multi-Agent Orchestrator
from core_crewai.crew_orchestrator import CrewOrchestrator
from core_crewai.models import PsychologicalSummary, BookRecommendation

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (CrewAI Orchestrator)
orchestrator = CrewOrchestrator()

# ëŒ€í™” ì €ì¥ì†Œ ë° ë¶„ì„ ìƒíƒœ ì¶”ì 
conversation_history = []
analysis_done = False  # ë¶„ì„ì´ ì´ë¯¸ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€ ì¶”ì 
current_summary = None  # í˜„ì¬ ë¶„ì„ ê²°ê³¼ ì €ì¥
books_recommended = False  # ì±… ì¶”ì²œì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ ì¶”ì 


def count_assistant_messages(history: List) -> int:
    """íˆìŠ¤í† ë¦¬ì—ì„œ assistant ë©”ì‹œì§€ ê°œìˆ˜ ì„¸ê¸°"""
    count = 0
    if history:
        for msg in history:
            if isinstance(msg, dict) and msg.get("role") == "assistant":
                count += 1
            elif isinstance(msg, tuple) and len(msg) == 2:
                # íŠœí”Œ í˜•ì‹ì¸ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
                count += 1
    return count


def clean_message(msg: dict) -> dict:
    """
    ë©”ì‹œì§€ì—ì„œ roleê³¼ contentë§Œ ì¶”ì¶œ (Anthropic API í˜¸í™˜)
    Gradioê°€ ì¶”ê°€í•˜ëŠ” metadata ë“± ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
    """
    return {
        "role": msg.get("role", "user"),
        "content": msg.get("content", "")
    }


def format_analysis_only(summary: PsychologicalSummary) -> str:
    """ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ë§Œ ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ… (ì±… ì¶”ì²œ ì—†ìŒ)"""
    result = "## ğŸ“Š ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼\n\n"
    
    result += "### ğŸ¯ ì£¼ìš” ê³ ë¯¼\n"
    for concern in summary.main_concerns:
        result += f"- {concern}\n"
    result += "\n"
    
    result += "### ğŸ’­ ê°ì • ìƒíƒœ\n"
    for emotion in summary.emotions:
        result += f"- {emotion}\n"
    result += "\n"
    
    result += "### ğŸ§  ì¸ì§€ íŒ¨í„´\n"
    for pattern in summary.cognitive_patterns:
        result += f"- {pattern}\n"
    result += "\n"
    
    result += "### ğŸ’¡ ê¶Œì¥ ì „ëµ\n"
    for rec in summary.recommendations:
        result += f"- {rec}\n"
    result += "\n"
    
    result += f"### ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ\n{', '.join(summary.keywords)}\n\n"
    
    # ì±… ì¶”ì²œ ì œì•ˆ ë©”ì‹œì§€ ì¶”ê°€
    result += "---\n\n"
    result += "ì¶©ë¶„í•œ ìƒë‹´ì´ ëë‚œ ê²ƒ ê°™ì€ë° ì±…ì„ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
    
    return result


def format_books_recommendation(books: List[BookRecommendation], summary: PsychologicalSummary) -> str:
    """ì±… ì¶”ì²œ ê²°ê³¼ë§Œ ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""
    result = "## ğŸ“š ì¶”ì²œ ë„ì„œ\n\n"
    
    if books:
        for i, book in enumerate(books, 1):
            result += f"**{i}. {book.title}** - {book.author}\n"
            result += f"- ì¶œíŒì‚¬: {book.publisher}\n"
            result += f"- ì¶”ì²œ ì´ìœ : {book.relevance_reason}\n"
            if book.link:
                result += f"- [ë„¤ì´ë²„ ë„ì„œ ë³´ê¸°]({book.link})\n"
            result += "\n"
    else:
        result += "âš ï¸ ë„ì„œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
        result += f"ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ì§ì ‘ ê²€ìƒ‰í•´ë³´ì„¸ìš”: {', '.join(summary.keywords)}\n"
    
    return result


def format_analysis_result(summary: PsychologicalSummary, books: List) -> str:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ… (í•˜ìœ„ í˜¸í™˜ì„±ìš©)"""
    result = format_analysis_only(summary)
    result = result.replace("ì¶©ë¶„í•œ ìƒë‹´ì´ ëë‚œ ê²ƒ ê°™ì€ë° ì±…ì„ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?", "")
    result += "\n" + format_books_recommendation(books, summary)
    return result


async def chat_with_bot(message: str, history: List) -> Tuple[List, str, bool, str]:
    """
    ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ê³¼ ëŒ€í™”
    5íšŒ ì´ìƒì˜ assistant ì‘ë‹µì„ ë°›ìœ¼ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ ë° ì¶”ì²œ ì‹¤í–‰
    
    Args:
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        history: ëŒ€í™” ê¸°ë¡ (Gradio 6.0 í˜•ì‹)
    
    Returns:
        (ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ê¸°ë¡, ìƒíƒœ ë©”ì‹œì§€, ì¥ë¥´ ë“œë¡­ë‹¤ìš´ í‘œì‹œ ì—¬ë¶€, ì¥ë¥´ ì•ˆë‚´ ë©”ì‹œì§€)
    """
    global conversation_history, analysis_done
    
    if not message.strip():
        return history, "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    # Gradio 6.0 í˜•ì‹ì—ì„œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë©”íƒ€ë°ì´í„° ì œê±°)
    messages = []
    if history:
        if isinstance(history[0], dict):
            for msg in history:
                if "role" in msg and "content" in msg:
                    messages.append(clean_message(msg))
        elif isinstance(history[0], tuple):
            for user_msg, bot_msg in history:
                messages.append({"role": "user", "content": user_msg})
                messages.append({"role": "assistant", "content": bot_msg})
    
    # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
    messages.append({"role": "user", "content": message})
    
    # assistant ë©”ì‹œì§€ ê°œìˆ˜ í™•ì¸ (í˜„ì¬ ì‘ë‹µ ì „)
    assistant_count_before = count_assistant_messages(history)
    
    # 5ë²ˆì§¸ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ì „ì— (4ë²ˆì§¸ ì‘ë‹µê¹Œì§€ ë°›ì€ ìƒíƒœ) ëë§ºëŠ” ë§ì„ í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    is_last_response = (assistant_count_before == 4 and not analysis_done)
    
    try:
        # ë§ˆì§€ë§‰ ì‘ë‹µì¸ ê²½ìš° ëë§ºëŠ” ë§ì„ í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if is_last_response:
            closing_prompt = "\n\n[ì¤‘ìš”: ì´ê²ƒì´ ì´ë²ˆ ìƒë‹´ì˜ ë§ˆì§€ë§‰ ì‘ë‹µì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” ë§ˆë¬´ë¦¬ ì¸ì‚¬ë¥¼ í•˜ë˜, ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì§€ ë§ê³  ìƒë‹´ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”. ì˜ˆ: 'ì˜¤ëŠ˜ ëŒ€í™”ë¥¼ í†µí•´ ë§ì€ ê²ƒì„ ë‚˜ëˆˆ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œë„ í˜ë‚´ì‹œê¸¸ ë°”ë¼ë©°, í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë‹¤ì‹œ ì°¾ì•„ì£¼ì„¸ìš”.'ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.]"
            messages[-1]["content"] = message + closing_prompt
        
        # CrewAI Orchestratorë¥¼ í†µí•œ ì±—ë´‡ ì‘ë‹µ ìƒì„±
        # orchestrator.chat()ëŠ” ì´ì œ (ì‘ë‹µ, ë¶„ì„ì¤€ë¹„ì—¬ë¶€) íŠœí”Œ ë°˜í™˜
        response, analysis_ready = orchestrator.chat(message, history)
        
        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        conversation_history = messages + [{"role": "assistant", "content": response}]
        
        # Gradio íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": response})
        
        # assistant ë©”ì‹œì§€ ê°œìˆ˜ í™•ì¸
        assistant_count = count_assistant_messages(history)
        
        # LLMì´ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œë¥¼ íŒë‹¨í–ˆê±°ë‚˜, 5íšŒ ì´ìƒ ëŒ€í™”í–ˆë‹¤ë©´ ìë™ ë¶„ì„ ì‹¤í–‰
        if (analysis_ready or assistant_count >= 5) and not analysis_done:
            status = f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(conversation_history)}ê°œ ë©”ì‹œì§€)\n\n"
            if analysis_ready:
                status += "ğŸ¤– AIê°€ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆë‹¤ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
            else:
                status += "ğŸ” 5íšŒ ëŒ€í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
            
            # ì‹¬ë¦¬ ë¶„ì„ë§Œ ì‹¤í–‰ (ì±… ì¶”ì²œì€ ë‚˜ì¤‘ì—) - CrewAI Orchestrator ì‚¬ìš©
            try:
                summary = orchestrator.analyze_conversation(conversation_history)
                
                # ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
                global current_summary
                current_summary = summary
                
                # ë¶„ì„ ê²°ê³¼ë§Œ ì±„íŒ… ë©”ì‹œì§€ë¡œ ì¶”ê°€ (ì±… ì¶”ì²œ ì œì•ˆ í¬í•¨)
                analysis_result = format_analysis_only(summary)
                history.append({
                    "role": "assistant",
                    "content": analysis_result
                })
                
                # conversation_historyì—ë„ ì¶”ê°€
                conversation_history.append({
                    "role": "assistant",
                    "content": analysis_result
                })
                
                analysis_done = True
                status += "\nâœ… ì‹¬ë¦¬ ë¶„ì„ ì™„ë£Œ! ì„ í˜¸ ì¥ë¥´ë¥¼ ì„ íƒí•œ í›„ 'ğŸ“š ì±… ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                
                # ì¥ë¥´ ì„ íƒ UI í‘œì‹œ
                return history, status, True, "ğŸ’¡ ì¥ë¥´ë¥¼ ì„ íƒí•˜ë©´ ë” ì •í™•í•œ ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                
            except Exception as analysis_error:
                import traceback
                print(f"ë¶„ì„ ì˜¤ë¥˜: {traceback.format_exc()}")
                error_msg = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(analysis_error)}"
                history.append({
                    "role": "assistant",
                    "content": f"âš ï¸ {error_msg}"
                })
                status += f"\nâŒ ë¶„ì„ ì‹¤íŒ¨: {str(analysis_error)}"
                return history, status, False, ""
        else:
            if analysis_done:
                status = f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(conversation_history)}ê°œ ë©”ì‹œì§€) - ë¶„ì„ ì™„ë£Œë¨"
                return history, status, True, "ğŸ’¡ ì¥ë¥´ë¥¼ ì„ íƒí•˜ë©´ ë” ì •í™•í•œ ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            else:
                status = f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(conversation_history)}ê°œ ë©”ì‹œì§€)\n"
                status += f"ğŸ’¡ AIê°€ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆë‹¤ê³  íŒë‹¨í•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.\n"
                if assistant_count < 5:
                    remaining = 5 - assistant_count
                    status += f"   (ë˜ëŠ” {remaining}íšŒ ë” ëŒ€í™” í›„ ìë™ ë¶„ì„)"
        
        return history, status, False, ""
    
    except Exception as e:
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": error_msg})
        return history, f"âŒ ì˜¤ë¥˜: {str(e)}", False, ""


async def manual_analyze_and_recommend(history: List, selected_genre: str) -> Tuple[List, str, bool, str]:
    """
    ìˆ˜ë™ìœ¼ë¡œ ë¶„ì„ ë° ë„ì„œ ì¶”ì²œ ì‹¤í–‰
    - ë¶„ì„ì´ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´: ì‹¬ë¦¬ ë¶„ì„ ìˆ˜í–‰ + ì±… ì¶”ì²œ ì œì•ˆ
    - ë¶„ì„ì´ ë˜ì–´ ìˆìœ¼ë©´: ì±… ì¶”ì²œ ìˆ˜í–‰
    
    Args:
        history: ëŒ€í™” ê¸°ë¡
        selected_genre: ì„ íƒëœ ì¥ë¥´
    
    Returns:
        (ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ê¸°ë¡, ìƒíƒœ ë©”ì‹œì§€, ì¥ë¥´ ë“œë¡­ë‹¤ìš´ í‘œì‹œ ì—¬ë¶€, ì¥ë¥´ ì•ˆë‚´ ë©”ì‹œì§€)
    """
    global conversation_history, analysis_done, current_summary, books_recommended
    
    # íˆìŠ¤í† ë¦¬ì—ì„œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë©”íƒ€ë°ì´í„° ì œê±°)
    messages = []
    if history:
        if isinstance(history[0], dict):
            for msg in history:
                if "role" in msg and "content" in msg:
                    messages.append(clean_message(msg))
        elif isinstance(history[0], tuple):
            for user_msg, bot_msg in history:
                messages.append({"role": "user", "content": user_msg})
                messages.append({"role": "assistant", "content": bot_msg})
    
    if not messages:
        return history, "âŒ ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒë‹´ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.", False, ""
    
    # conversation_history ì—…ë°ì´íŠ¸
    conversation_history = messages
    
    try:
        # ì´ë¯¸ ì±… ì¶”ì²œì´ ì™„ë£Œëœ ê²½ìš°
        if books_recommended:
            return history, "â„¹ï¸ ì´ë¯¸ ì±… ì¶”ì²œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì´ˆê¸°í™”í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", False, ""
        
        # ë¶„ì„ì´ ì´ë¯¸ ì™„ë£Œëœ ê²½ìš° -> ì±… ì¶”ì²œë§Œ ìˆ˜í–‰
        if analysis_done and current_summary:
            status = f"ğŸ“š '{selected_genre}' ì¥ë¥´ ì¤‘ì‹¬ìœ¼ë¡œ ì±…ì„ ê²€ìƒ‰í•˜ê³  ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
            
            # ì¥ë¥´ ì •ë³´ë¥¼ summaryì— ì¶”ê°€
            current_summary.genre = selected_genre
            
            # CrewAI Orchestratorë¥¼ í†µí•œ ë„ì„œ ì¶”ì²œ
            books = orchestrator.recommend_books_from_summary(current_summary, max_books=5)
            
            # ì±… ì¶”ì²œ ê²°ê³¼ë¥¼ ì±„íŒ… ë©”ì‹œì§€ë¡œ ì¶”ê°€
            books_result = format_books_recommendation(books, current_summary)
            history.append({
                "role": "assistant",
                "content": books_result
            })
            
            # conversation_historyì—ë„ ì¶”ê°€
            conversation_history.append({
                "role": "assistant",
                "content": books_result
            })
            
            books_recommended = True
            status = f"âœ… ì±… ì¶”ì²œ ì™„ë£Œ! ({len(books)}ê¶Œ ì¶”ì²œ)"
            
            # ì¥ë¥´ ë“œë¡­ë‹¤ìš´ ìˆ¨ê¸°ê¸°
            return history, status, False, ""
        
        # ë¶„ì„ì´ ì•ˆ ë˜ì–´ ìˆëŠ” ê²½ìš° -> ì‹¬ë¦¬ ë¶„ì„ ìˆ˜í–‰ + ì±… ì¶”ì²œ ì œì•ˆ
        # ë¨¼ì € AIì˜ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì±„íŒ…ì— ì¶”ê°€
        intro_message = "ì§€ê¸ˆê¹Œì§€ ë‚˜ëˆˆ ëŒ€í™”ë¥¼ í†µí•´ ë„ì›€ì´ ë  ë§Œí•œ ì±…ì„ ì¶”ì²œí•´ì¤„ê²Œìš”"
        history.append({
            "role": "assistant",
            "content": intro_message
        })
        conversation_history.append({
            "role": "assistant",
            "content": intro_message
        })
        
        status = "ğŸ” ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
        
        # CrewAI Orchestratorë¥¼ í†µí•œ ì‹¬ë¦¬ ë¶„ì„ ì‹¤í–‰
        summary = orchestrator.analyze_conversation(conversation_history)
        
        # ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
        current_summary = summary
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì±„íŒ… ë©”ì‹œì§€ë¡œ ì¶”ê°€ (ì±… ì¶”ì²œ ì œì•ˆ í¬í•¨)
        analysis_result = format_analysis_only(summary)
        history.append({
            "role": "assistant",
            "content": analysis_result
        })
        
        # conversation_historyì—ë„ ì¶”ê°€
        conversation_history.append({
            "role": "assistant",
            "content": analysis_result
        })
        
        analysis_done = True
        status = "âœ… ì‹¬ë¦¬ ë¶„ì„ ì™„ë£Œ! ì„ í˜¸ ì¥ë¥´ë¥¼ ì„ íƒí•œ í›„ 'ğŸ“š ì±… ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        
        # ì¥ë¥´ ì„ íƒ UI í‘œì‹œ
        return history, status, True, "ğŸ’¡ ì¥ë¥´ë¥¼ ì„ íƒí•˜ë©´ ë” ì •í™•í•œ ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ìˆ˜ë™ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {error_detail}")
        error_msg = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        return history, f"âŒ {error_msg}", False, ""


def clear_conversation() -> Tuple[List, str, bool, str]:
    """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
    global conversation_history, analysis_done, current_summary, books_recommended
    conversation_history = []
    analysis_done = False
    current_summary = None
    books_recommended = False
    return [], "ğŸ”„ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.", False, ""


def export_conversation() -> str:
    """ëŒ€í™” ë‚´ìš©ì„ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    global conversation_history
    
    if not conversation_history:
        return "ë‚´ë³´ë‚¼ ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    
    export_data = {
        "exported_at": datetime.now().isoformat(),
        "message_count": len(conversation_history),
        "messages": conversation_history
    }
    
    return json.dumps(export_data, ensure_ascii=False, indent=2)


# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± (ë‹¨ì¼ íƒ­)
with gr.Blocks(
    title="ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ + ë„ì„œ ì¶”ì²œ"
) as demo:
    
    # í—¤ë”
    gr.Markdown("""
    # ğŸ§  ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ + ğŸ“š ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ
    
    **CrewAI ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ** ê¸°ë°˜ ì‹¬ë¦¬ ìƒë‹´ ë° ë„ì„œ ì¶”ì²œ ì„œë¹„ìŠ¤
    
    ### ì‚¬ìš© ë°©ë²•
    1. ê³ ë¯¼ì´ë‚˜ ê°ì •ì„ ììœ ë¡­ê²Œ ì´ì•¼ê¸°í•˜ì„¸ìš”
    2. **AIê°€ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆë‹¤ê³  íŒë‹¨í•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤**
       - ë˜ëŠ” 5íšŒ ëŒ€í™” í›„ ìë™ ë¶„ì„ (ì•ˆì „ì¥ì¹˜)
    3. ì¶”ì²œëœ ë„ì„œë¥¼ í†µí•´ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”
    
    ### ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
    - **Counselor Agent**: ê³µê°ì  ê²½ì²­ê³¼ ë°ì´í„° ìˆ˜ì§‘ (LLMì´ ì •ë³´ ì¶©ë¶„ì„± íŒë‹¨)
    - **Psychological Analyzer Agent**: SKILL.md í”„ë ˆì„ì›Œí¬ ê¸°ë°˜ ì‹¬ì¸µ ì‹¬ë¦¬ ë¶„ì„
    - **Book Recommender Agent**: ë§ì¶¤í˜• ë…ì„œ ì¹˜ë£Œ ë„ì„œ ì¶”ì²œ
    
    **ë¶„ì„ í”„ë ˆì„ì›Œí¬:** SKILL.md (ì¸ì§€ì‹¬ë¦¬í•™, ì‚¬íšŒì‹¬ë¦¬í•™, ì„ìƒì‹¬ë¦¬í•™, ë°œë‹¬ì‹¬ë¦¬í•™, ì‹ ê²½ê³¼í•™)
    """)
    
    # ìƒíƒœ í‘œì‹œ
    status_box = gr.Textbox(
        label="ìƒíƒœ",
        value="ì¤€ë¹„ë¨ - ëŒ€í™”ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”",
        interactive=False,
        max_lines=3
    )
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    chatbot_interface = gr.Chatbot(
        label="ëŒ€í™”",
        elem_id="chatbot",
        height=600,
        show_label=True,
        avatar_images=(None, "ğŸ¤–")
    )
    
    # ë©”ì‹œì§€ ì…ë ¥ ì˜ì—­
    with gr.Row():
        msg_input = gr.Textbox(
            label="ë©”ì‹œì§€ ì…ë ¥",
            placeholder="ê³ ë¯¼ì´ë‚˜ ê°ì •ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”...",
            scale=4,
            max_lines=3,
            container=False
        )
        submit_btn = gr.Button("ì „ì†¡", scale=1, variant="primary", size="lg")
    
    # ì¥ë¥´ ì„ íƒ (ë¶„ì„ í›„ í‘œì‹œ)
    genre_dropdown = gr.Dropdown(
        label="ğŸ“– ì„ í˜¸í•˜ëŠ” ì±… ì¥ë¥´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”",
        choices=["ìê¸°ê³„ë°œ", "ì‹¬ë¦¬í•™", "ì†Œì„¤", "ì—ì„¸ì´", "ì¸ë¬¸", "ê²½ì œ/ê²½ì˜", "ê¸°íƒ€"],
        value="ìê¸°ê³„ë°œ",
        interactive=True,
        visible=False
    )
    genre_info = gr.Markdown("", visible=False)
    
    # ì»¨íŠ¸ë¡¤ ë²„íŠ¼
    with gr.Row():
        recommend_btn = gr.Button("ğŸ“š ì±… ì¶”ì²œë°›ê¸°", variant="primary", size="lg")
        clear_btn = gr.Button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", variant="secondary")
        export_btn = gr.Button("ğŸ’¾ ëŒ€í™” ë‚´ë³´ë‚´ê¸°", variant="secondary")
    
    # ë‚´ë³´ë‚´ê¸° ì¶œë ¥ (ìˆ¨ê¹€)
    export_output = gr.Textbox(
        label="ë‚´ë³´ë‚¸ ëŒ€í™” (JSON)",
        lines=10,
        visible=False
    )
    
    # ì•ˆë‚´ ë©”ì‹œì§€
    gr.Markdown("""
    ---
    
    ### ğŸ’¡ ì•ˆë‚´ì‚¬í•­
    
    - **ğŸ¤– ì§€ëŠ¥í˜• ë¶„ì„**: AIê°€ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆë‹¤ê³  íŒë‹¨í•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ ì‹œì‘
      - AI íŒë‹¨ ê¸°ì¤€: ì£¼ìš” ê³ ë¯¼, ê°ì •, ìƒí™©, ì›ì¸ ì¸ì‹, ëŒ€ì²˜ ë°©ì‹ íŒŒì•… ì™„ë£Œ
      - ì•ˆì „ì¥ì¹˜: 5íšŒ ëŒ€í™” í›„ ìë™ ë¶„ì„ (ì •ë³´ ë¶€ì¡± ì‹œ)
    - **ìˆ˜ë™ ë¶„ì„**: ì–¸ì œë“ ì§€ "ğŸ“š ì±… ì¶”ì²œë°›ê¸°" ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë¶„ì„ ë° ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - **ëŒ€í™” ê¸°ë¡**: ëª¨ë“  ëŒ€í™” ë‚´ìš©ì´ ìœ„ì— í‘œì‹œë©ë‹ˆë‹¤
    - **ê°œì¸ì •ë³´**: ë¯¼ê°í•œ ê°œì¸ì •ë³´ëŠ” ì…ë ¥í•˜ì§€ ë§ˆì„¸ìš”
    
    ### ğŸ¤– CrewAI ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
    
    ì´ ì‹œìŠ¤í…œì€ ì„¸ ê°œì˜ ì „ë¬¸ AI ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥í•˜ì—¬ ì‘ë™í•©ë‹ˆë‹¤:
    
    1. **Counselor Agent** ğŸ§‘â€âš•ï¸
       - ê³µê°ì  ê²½ì²­ê³¼ í•µì‹¬ ì •ë³´ ìˆ˜ì§‘
       - SKILL.mdì˜ ì‚¬íšŒì‹¬ë¦¬í•™ ì›ë¦¬ ì ìš©
       
    2. **Psychological Analyzer Agent** ğŸ§ 
       - SKILL.md í”„ë ˆì„ì›Œí¬ ê¸°ë°˜ 6ë‹¨ê³„ ë¶„ì„
       - ì¸ì§€/ì‚¬íšŒ/ì„ìƒ/ë°œë‹¬ ì‹¬ë¦¬í•™ í†µí•© ë¶„ì„
       
    3. **Book Recommender Agent** ğŸ“š
       - ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ë§ì¶¤ ë„ì„œ ì¶”ì²œ
       - ë„¤ì´ë²„ ë„ì„œ API í™œìš©
    
    âš ï¸ **ì´ ì±—ë´‡ì€ ì „ë¬¸ì ì¸ ì‹¬ë¦¬ ìƒë‹´ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**
    ìœ„ê¸° ìƒí™©ì´ë‚˜ ì‹¬ê°í•œ ì‹¬ë¦¬ì  ë¬¸ì œê°€ ìˆë‹¤ë©´ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.
    """)
    
    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
    async def submit_message(message, history):
        """ë©”ì‹œì§€ ì „ì†¡ ì²˜ë¦¬ (async)"""
        new_history, status, show_genre, genre_msg = await chat_with_bot(message, history)
        return new_history, status, "", gr.update(visible=show_genre), gr.update(value=genre_msg, visible=show_genre)
    
    submit_btn.click(
        fn=submit_message,
        inputs=[msg_input, chatbot_interface],
        outputs=[chatbot_interface, status_box, msg_input, genre_dropdown, genre_info]
    )
    
    msg_input.submit(
        fn=submit_message,
        inputs=[msg_input, chatbot_interface],
        outputs=[chatbot_interface, status_box, msg_input, genre_dropdown, genre_info]
    )
    
    # ì±… ì¶”ì²œë°›ê¸° ë²„íŠ¼ ì´ë²¤íŠ¸
    recommend_btn.click(
        fn=manual_analyze_and_recommend,
        inputs=[chatbot_interface, genre_dropdown],
        outputs=[chatbot_interface, status_box, genre_dropdown, genre_info]
    )
    
    clear_btn.click(
        fn=clear_conversation,
        outputs=[chatbot_interface, status_box, genre_dropdown, genre_info]
    )
    
    export_btn.click(
        fn=export_conversation,
        outputs=[export_output]
    ).then(
        fn=lambda: gr.Textbox(visible=True),
        outputs=[export_output]
    )
    
    # í‘¸í„°
    gr.Markdown("""
    ---
    
    Made with â¤ï¸ using CrewAI, Claude AI (Sonnet 4), SKILL.md Framework, and Gradio
    
    **Architecture**: Multi-Agent System with Sequential Workflow
    """)


# ì•± ì‹¤í–‰
if __name__ == "__main__":
    print("=" * 60)
    print("CrewAI ë©€í‹° ì—ì´ì „íŠ¸ ì‹¬ë¦¬ ìƒë‹´ + ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ")
    print("=" * 60)
    print("\nğŸ¤– ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ:")
    print("  - Counselor Agent (ê²½ì²­ & ë°ì´í„° ìˆ˜ì§‘)")
    print("  - Psychological Analyzer Agent (SKILL.md ê¸°ë°˜ ë¶„ì„)")
    print("  - Book Recommender Agent (ë§ì¶¤ ë„ì„œ ì¶”ì²œ)")
    print("\nì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤.")
    print("=" * 60 + "\n")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False,
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 1400px !important;
        }
        #chatbot {
            height: 600px;
        }
        """
    )

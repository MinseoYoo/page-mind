"""
Gradio ì›¹ ë°ëª¨ - ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ + ë„ì„œ ì¶”ì²œ
ë‹¨ì¼ íƒ­ êµ¬ì„±, 5íšŒ ì´ìƒ ëŒ€í™” ì‹œ ìë™ ë¶„ì„ ë° ì¶”ì²œ
"""

import sys
import platform
import asyncio

# Windowsì—ì„œ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì •ì±… ì„¤ì • (Gradio ì‹œì‘ ì „ì—)
if platform.system() == 'Windows':
    if sys.version_info >= (3, 8):
        # Windowsì—ì„œ SelectorEventLoop ì‚¬ìš© (ProactorEventLoop ëŒ€ì‹ )
        # ProactorEventLoopëŠ” socket.socketpair()ì—ì„œ ë¬¸ì œ ë°œìƒ
        try:
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        except AttributeError:
            # Python 3.7 ì´í•˜ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€
            pass

import gradio as gr
from datetime import datetime
from typing import List, Tuple
import json
import os

from dotenv import load_dotenv
load_dotenv()
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

from core.psychology_chatbot import PsychologyChatbot
from core.counseling_analyzer import CounselingAnalyzer
from core.book_recommender import BookRecommender
from core.models import PsychologicalSummary, BookRecommendation

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chatbot = PsychologyChatbot(ANTHROPIC_API_KEY)
analyzer = CounselingAnalyzer(ANTHROPIC_API_KEY)
recommender = BookRecommender(ANTHROPIC_API_KEY)

# ëŒ€í™” ì €ì¥ì†Œ ë° ë¶„ì„ ìƒíƒœ ì¶”ì 
conversation_history = []
analysis_done = False  # ë¶„ì„ì´ ì´ë¯¸ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€ ì¶”ì 
current_summary = None  # í˜„ì¬ ë¶„ì„ ê²°ê³¼ ì €ì¥
books_recommended = False  # ì±… ì¶”ì²œì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ ì¶”ì 


def count_assistant_messages(history: List) -> int:
    """íˆìŠ¤í† ë¦¬ì—ì„œ assistant ë©”ì‹œì§€ ê°œìˆ˜ ì„¸ê¸°"""
    count = 0
    if history:
        for msg in history:
            if isinstance(msg, dict) and msg.get("role") == "assistant":
                count += 1
            elif isinstance(msg, tuple) and len(msg) == 2:
                # íŠœí”Œ í˜•ì‹ì¸ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
                count += 1
    return count


def format_analysis_only(summary: PsychologicalSummary) -> str:
    """ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ë§Œ ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ… (ì±… ì¶”ì²œ ì—†ìŒ)"""
    result = "## ğŸ“Š ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼\n\n"
    
    result += "### ğŸ¯ ì£¼ìš” ê³ ë¯¼\n"
    for concern in summary.main_concerns:
        result += f"- {concern}\n"
    result += "\n"
    
    result += "### ğŸ’­ ê°ì • ìƒíƒœ\n"
    for emotion in summary.emotions:
        result += f"- {emotion}\n"
    result += "\n"
    
    result += "### ğŸ§  ì¸ì§€ íŒ¨í„´\n"
    for pattern in summary.cognitive_patterns:
        result += f"- {pattern}\n"
    result += "\n"
    
    result += "### ğŸ’¡ ê¶Œì¥ ì „ëµ\n"
    for rec in summary.recommendations:
        result += f"- {rec}\n"
    result += "\n"
    
    result += f"### ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ\n{', '.join(summary.keywords)}\n\n"
    
    # ì±… ì¶”ì²œ ì œì•ˆ ë©”ì‹œì§€ ì¶”ê°€
    result += "---\n\n"
    result += "ì¶©ë¶„í•œ ìƒë‹´ì´ ëë‚œ ê²ƒ ê°™ì€ë° ì±…ì„ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
    
    return result


def format_books_recommendation(books: List[BookRecommendation], summary: PsychologicalSummary) -> str:
    """ì±… ì¶”ì²œ ê²°ê³¼ë§Œ ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""
    result = "## ğŸ“š ì¶”ì²œ ë„ì„œ\n\n"
    
    if books:
        for i, book in enumerate(books, 1):
            result += f"**{i}. {book.title}** - {book.author}\n"
            result += f"- ì¶œíŒì‚¬: {book.publisher}\n"
            result += f"- ì¶”ì²œ ì´ìœ : {book.relevance_reason}\n"
            if book.link:
                result += f"- [ë„¤ì´ë²„ ë„ì„œ ë³´ê¸°]({book.link})\n"
            result += "\n"
    else:
        result += "âš ï¸ ë„ì„œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
        result += f"ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ì§ì ‘ ê²€ìƒ‰í•´ë³´ì„¸ìš”: {', '.join(summary.keywords)}\n"
    
    return result


def format_analysis_result(summary: PsychologicalSummary, books: List) -> str:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ… (í•˜ìœ„ í˜¸í™˜ì„±ìš©)"""
    result = format_analysis_only(summary)
    result = result.replace("ì¶©ë¶„í•œ ìƒë‹´ì´ ëë‚œ ê²ƒ ê°™ì€ë° ì±…ì„ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?", "")
    result += "\n" + format_books_recommendation(books, summary)
    return result


async def chat_with_bot(message: str, history: List) -> Tuple[List, str]:
    """
    ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ê³¼ ëŒ€í™”
    5íšŒ ì´ìƒì˜ assistant ì‘ë‹µì„ ë°›ìœ¼ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ ë° ì¶”ì²œ ì‹¤í–‰
    
    Args:
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        history: ëŒ€í™” ê¸°ë¡ (Gradio 6.0 í˜•ì‹)
    
    Returns:
        (ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ê¸°ë¡, ìƒíƒœ ë©”ì‹œì§€)
    """
    global conversation_history, analysis_done
    
    if not message.strip():
        return history, "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    # Gradio 6.0 í˜•ì‹ì—ì„œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    messages = []
    if history:
        if isinstance(history[0], dict):
            for msg in history:
                if "role" in msg and "content" in msg:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
        elif isinstance(history[0], tuple):
            for user_msg, bot_msg in history:
                messages.append({"role": "user", "content": user_msg})
                messages.append({"role": "assistant", "content": bot_msg})
    
    # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
    messages.append({"role": "user", "content": message})
    
    # assistant ë©”ì‹œì§€ ê°œìˆ˜ í™•ì¸ (í˜„ì¬ ì‘ë‹µ ì „)
    assistant_count_before = count_assistant_messages(history)
    
    # 5ë²ˆì§¸ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ì „ì— (4ë²ˆì§¸ ì‘ë‹µê¹Œì§€ ë°›ì€ ìƒíƒœ) ëë§ºëŠ” ë§ì„ í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    is_last_response = (assistant_count_before == 4 and not analysis_done)
    
    try:
        # ë§ˆì§€ë§‰ ì‘ë‹µì¸ ê²½ìš° ëë§ºëŠ” ë§ì„ í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if is_last_response:
            closing_prompt = "\n\n[ì¤‘ìš”: ì´ê²ƒì´ ì´ë²ˆ ìƒë‹´ì˜ ë§ˆì§€ë§‰ ì‘ë‹µì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” ë§ˆë¬´ë¦¬ ì¸ì‚¬ë¥¼ í•˜ë˜, ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì§€ ë§ê³  ìƒë‹´ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”. ì˜ˆ: 'ì˜¤ëŠ˜ ëŒ€í™”ë¥¼ í†µí•´ ë§ì€ ê²ƒì„ ë‚˜ëˆˆ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œë„ í˜ë‚´ì‹œê¸¸ ë°”ë¼ë©°, í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë‹¤ì‹œ ì°¾ì•„ì£¼ì„¸ìš”.'ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.]"
            messages[-1]["content"] = message + closing_prompt
        
        # ì±—ë´‡ ì‘ë‹µ ìƒì„±
        response = chatbot.chat(messages)
        
        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        conversation_history = messages + [{"role": "assistant", "content": response}]
        
        # Gradio íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": response})
        
        # assistant ë©”ì‹œì§€ ê°œìˆ˜ í™•ì¸
        assistant_count = count_assistant_messages(history)
        
        # 5íšŒ ì´ìƒì˜ assistant ì‘ë‹µì„ ë°›ì•˜ê³ , ì•„ì§ ë¶„ì„ì„ í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ìë™ ë¶„ì„ ì‹¤í–‰
        if assistant_count >= 5 and not analysis_done:
            status = f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(conversation_history)}ê°œ ë©”ì‹œì§€)\n\n"
            status += "ğŸ” ì¶©ë¶„í•œ ëŒ€í™”ê°€ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
            
            # ì‹¬ë¦¬ ë¶„ì„ë§Œ ì‹¤í–‰ (ì±… ì¶”ì²œì€ ë‚˜ì¤‘ì—)
            try:
                summary = analyzer.analyze_conversation(conversation_history)
                
                # ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
                global current_summary
                current_summary = summary
                
                # ë¶„ì„ ê²°ê³¼ë§Œ ì±„íŒ… ë©”ì‹œì§€ë¡œ ì¶”ê°€ (ì±… ì¶”ì²œ ì œì•ˆ í¬í•¨)
                analysis_result = format_analysis_only(summary)
                history.append({
                    "role": "assistant",
                    "content": analysis_result
                })
                
                # conversation_historyì—ë„ ì¶”ê°€
                conversation_history.append({
                    "role": "assistant",
                    "content": analysis_result
                })
                
                analysis_done = True
                status += "\nâœ… ì‹¬ë¦¬ ë¶„ì„ ì™„ë£Œ! ì±… ì¶”ì²œì„ ì›í•˜ì‹œë©´ 'ğŸ“š ì±… ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                
            except Exception as analysis_error:
                import traceback
                print(f"ë¶„ì„ ì˜¤ë¥˜: {traceback.format_exc()}")
                error_msg = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(analysis_error)}"
                history.append({
                    "role": "assistant",
                    "content": f"âš ï¸ {error_msg}"
                })
                status += f"\nâŒ ë¶„ì„ ì‹¤íŒ¨: {str(analysis_error)}"
        else:
            if analysis_done:
                status = f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(conversation_history)}ê°œ ë©”ì‹œì§€) - ë¶„ì„ ì™„ë£Œë¨"
            else:
                remaining = 5 - assistant_count
                status = f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(conversation_history)}ê°œ ë©”ì‹œì§€)\n"
                status += f"ğŸ’¡ {remaining}íšŒ ë” ëŒ€í™”í•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤."
        
        return history, status
    
    except Exception as e:
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": error_msg})
        return history, f"âŒ ì˜¤ë¥˜: {str(e)}"


async def manual_analyze_and_recommend(history: List) -> Tuple[List, str]:
    """
    ìˆ˜ë™ìœ¼ë¡œ ë¶„ì„ ë° ë„ì„œ ì¶”ì²œ ì‹¤í–‰
    - ë¶„ì„ì´ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´: ì‹¬ë¦¬ ë¶„ì„ ìˆ˜í–‰ + ì±… ì¶”ì²œ ì œì•ˆ
    - ë¶„ì„ì´ ë˜ì–´ ìˆìœ¼ë©´: ì±… ì¶”ì²œ ìˆ˜í–‰
    
    Args:
        history: ëŒ€í™” ê¸°ë¡
    
    Returns:
        (ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ê¸°ë¡, ìƒíƒœ ë©”ì‹œì§€)
    """
    global conversation_history, analysis_done, current_summary, books_recommended
    
    # íˆìŠ¤í† ë¦¬ì—ì„œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    messages = []
    if history:
        if isinstance(history[0], dict):
            for msg in history:
                if "role" in msg and "content" in msg:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
        elif isinstance(history[0], tuple):
            for user_msg, bot_msg in history:
                messages.append({"role": "user", "content": user_msg})
                messages.append({"role": "assistant", "content": bot_msg})
    
    if not messages:
        return history, "âŒ ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒë‹´ì„ ì§„í–‰í•´ì£¼ì„¸ìš”."
    
    # conversation_history ì—…ë°ì´íŠ¸
    conversation_history = messages
    
    try:
        # ì´ë¯¸ ì±… ì¶”ì²œì´ ì™„ë£Œëœ ê²½ìš°
        if books_recommended:
            return history, "â„¹ï¸ ì´ë¯¸ ì±… ì¶”ì²œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì´ˆê¸°í™”í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        # ë¶„ì„ì´ ì´ë¯¸ ì™„ë£Œëœ ê²½ìš° -> ì±… ì¶”ì²œë§Œ ìˆ˜í–‰
        if analysis_done and current_summary:
            status = "ğŸ“š ì±…ì„ ê²€ìƒ‰í•˜ê³  ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
            
            # ë„¤ì´ë²„ APIë¥¼ í†µí•œ ë„ì„œ ì¶”ì²œ
            books = await recommender.recommend_books(current_summary, max_books=5)
            
            # ì±… ì¶”ì²œ ê²°ê³¼ë¥¼ ì±„íŒ… ë©”ì‹œì§€ë¡œ ì¶”ê°€
            books_result = format_books_recommendation(books, current_summary)
            history.append({
                "role": "assistant",
                "content": books_result
            })
            
            # conversation_historyì—ë„ ì¶”ê°€
            conversation_history.append({
                "role": "assistant",
                "content": books_result
            })
            
            books_recommended = True
            status = f"âœ… ì±… ì¶”ì²œ ì™„ë£Œ! ({len(books)}ê¶Œ ì¶”ì²œ)"
            
            return history, status
        
        # ë¶„ì„ì´ ì•ˆ ë˜ì–´ ìˆëŠ” ê²½ìš° -> ì‹¬ë¦¬ ë¶„ì„ ìˆ˜í–‰ + ì±… ì¶”ì²œ ì œì•ˆ
        # ë¨¼ì € AIì˜ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì±„íŒ…ì— ì¶”ê°€
        intro_message = "ì§€ê¸ˆê¹Œì§€ ë‚˜ëˆˆ ëŒ€í™”ë¥¼ í†µí•´ ë„ì›€ì´ ë  ë§Œí•œ ì±…ì„ ì¶”ì²œí•´ì¤„ê²Œìš”"
        history.append({
            "role": "assistant",
            "content": intro_message
        })
        conversation_history.append({
            "role": "assistant",
            "content": intro_message
        })
        
        status = "ğŸ” ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
        
        # ì‹¬ë¦¬ ë¶„ì„ ì‹¤í–‰
        summary = analyzer.analyze_conversation(conversation_history)
        
        # ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
        current_summary = summary
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì±„íŒ… ë©”ì‹œì§€ë¡œ ì¶”ê°€ (ì±… ì¶”ì²œ ì œì•ˆ í¬í•¨)
        analysis_result = format_analysis_only(summary)
        history.append({
            "role": "assistant",
            "content": analysis_result
        })
        
        # conversation_historyì—ë„ ì¶”ê°€
        conversation_history.append({
            "role": "assistant",
            "content": analysis_result
        })
        
        analysis_done = True
        status = "âœ… ì‹¬ë¦¬ ë¶„ì„ ì™„ë£Œ! ì±… ì¶”ì²œì„ ì›í•˜ì‹œë©´ ë‹¤ì‹œ 'ğŸ“š ì±… ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        
        return history, status
    
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ìˆ˜ë™ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {error_detail}")
        error_msg = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        return history, f"âŒ {error_msg}"


def clear_conversation() -> Tuple[List, str]:
    """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
    global conversation_history, analysis_done, current_summary, books_recommended
    conversation_history = []
    analysis_done = False
    current_summary = None
    books_recommended = False
    return [], "ğŸ”„ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."


def export_conversation() -> str:
    """ëŒ€í™” ë‚´ìš©ì„ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    global conversation_history
    
    if not conversation_history:
        return "ë‚´ë³´ë‚¼ ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    
    export_data = {
        "exported_at": datetime.now().isoformat(),
        "message_count": len(conversation_history),
        "messages": conversation_history
    }
    
    return json.dumps(export_data, ensure_ascii=False, indent=2)


# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± (ë‹¨ì¼ íƒ­)
with gr.Blocks(
    title="ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ + ë„ì„œ ì¶”ì²œ"
) as demo:
    
    # í—¤ë”
    gr.Markdown("""
    # ğŸ§  ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ + ğŸ“š ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ
    
    AI ê¸°ë°˜ ì‹¬ë¦¬ ìƒë‹´ì„ ë°›ê³ , **5íšŒ ì´ìƒ ëŒ€í™”í•˜ë©´ ìë™ìœ¼ë¡œ** ë§ì¶¤í˜• ë„ì„œë¥¼ ì¶”ì²œë°›ìœ¼ì„¸ìš”.
    
    ### ì‚¬ìš© ë°©ë²•
    1. ê³ ë¯¼ì´ë‚˜ ê°ì •ì„ ììœ ë¡­ê²Œ ì´ì•¼ê¸°í•˜ì„¸ìš”
    2. **5íšŒ ì´ìƒ ëŒ€í™”í•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ ë° ë„ì„œ ì¶”ì²œì´ ì‹œì‘ë©ë‹ˆë‹¤**
    3. ì¶”ì²œëœ ë„ì„œë¥¼ í†µí•´ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”
    
    **ìƒë‹´ í”„ë ˆì„ì›Œí¬:** ì¸ì§€í–‰ë™ì¹˜ë£Œ(CBT), ìê¸°ê²°ì •ì´ë¡ , ìŠ¤íŠ¸ë ˆìŠ¤ ëŒ€ì²˜ ì „ëµ
    """)
    
    # ìƒíƒœ í‘œì‹œ
    status_box = gr.Textbox(
        label="ìƒíƒœ",
        value="ì¤€ë¹„ë¨ - ëŒ€í™”ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”",
        interactive=False,
        max_lines=3
    )
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    chatbot_interface = gr.Chatbot(
        label="ëŒ€í™”",
        elem_id="chatbot",
        height=600,
        show_label=True,
        avatar_images=(None, "ğŸ¤–")
    )
    
    # ë©”ì‹œì§€ ì…ë ¥ ì˜ì—­
    with gr.Row():
        msg_input = gr.Textbox(
            label="ë©”ì‹œì§€ ì…ë ¥",
            placeholder="ê³ ë¯¼ì´ë‚˜ ê°ì •ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”...",
            scale=4,
            max_lines=3,
            container=False
        )
        submit_btn = gr.Button("ì „ì†¡", scale=1, variant="primary", size="lg")
    
    # ì»¨íŠ¸ë¡¤ ë²„íŠ¼
    with gr.Row():
        recommend_btn = gr.Button("ğŸ“š ì±… ì¶”ì²œë°›ê¸°", variant="primary", size="lg")
        clear_btn = gr.Button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", variant="secondary")
        export_btn = gr.Button("ğŸ’¾ ëŒ€í™” ë‚´ë³´ë‚´ê¸°", variant="secondary")
    
    # ë‚´ë³´ë‚´ê¸° ì¶œë ¥ (ìˆ¨ê¹€)
    export_output = gr.Textbox(
        label="ë‚´ë³´ë‚¸ ëŒ€í™” (JSON)",
        lines=10,
        visible=False
    )
    
    # ì•ˆë‚´ ë©”ì‹œì§€
    gr.Markdown("""
    ---
    
    ### ğŸ’¡ ì•ˆë‚´ì‚¬í•­
    
    - **ìë™ ë¶„ì„**: 5íšŒ ì´ìƒì˜ ìƒë‹´ ì‘ë‹µì„ ë°›ìœ¼ë©´ ìë™ìœ¼ë¡œ ì‹¬ë¦¬ ë¶„ì„ê³¼ ë„ì„œ ì¶”ì²œì´ ì‹œì‘ë©ë‹ˆë‹¤
    - **ìˆ˜ë™ ë¶„ì„**: ì–¸ì œë“ ì§€ "ğŸ“š ì±… ì¶”ì²œë°›ê¸°" ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë¶„ì„ ë° ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - **ëŒ€í™” ê¸°ë¡**: ëª¨ë“  ëŒ€í™” ë‚´ìš©ì´ ìœ„ì— í‘œì‹œë©ë‹ˆë‹¤
    - **ê°œì¸ì •ë³´**: ë¯¼ê°í•œ ê°œì¸ì •ë³´ëŠ” ì…ë ¥í•˜ì§€ ë§ˆì„¸ìš”
    
    âš ï¸ **ì´ ì±—ë´‡ì€ ì „ë¬¸ì ì¸ ì‹¬ë¦¬ ìƒë‹´ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**
    ìœ„ê¸° ìƒí™©ì´ë‚˜ ì‹¬ê°í•œ ì‹¬ë¦¬ì  ë¬¸ì œê°€ ìˆë‹¤ë©´ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.
    """)
    
    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
    async def submit_message(message, history):
        """ë©”ì‹œì§€ ì „ì†¡ ì²˜ë¦¬ (async)"""
        new_history, status = await chat_with_bot(message, history)
        return new_history, status, ""
    
    submit_btn.click(
        fn=submit_message,
        inputs=[msg_input, chatbot_interface],
        outputs=[chatbot_interface, status_box, msg_input]
    )
    
    msg_input.submit(
        fn=submit_message,
        inputs=[msg_input, chatbot_interface],
        outputs=[chatbot_interface, status_box, msg_input]
    )
    
    # ì±… ì¶”ì²œë°›ê¸° ë²„íŠ¼ ì´ë²¤íŠ¸
    recommend_btn.click(
        fn=manual_analyze_and_recommend,
        inputs=[chatbot_interface],
        outputs=[chatbot_interface, status_box]
    )
    
    clear_btn.click(
        fn=clear_conversation,
        outputs=[chatbot_interface, status_box]
    )
    
    export_btn.click(
        fn=export_conversation,
        outputs=[export_output]
    ).then(
        fn=lambda: gr.Textbox(visible=True),
        outputs=[export_output]
    )
    
    # í‘¸í„°
    gr.Markdown("""
    ---
    
    Made with â¤ï¸ using Claude AI and Gradio
    """)


# ì•± ì‹¤í–‰
if __name__ == "__main__":
    print("=" * 60)
    print("ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ + ë„ì„œ ì¶”ì²œ Gradio ë°ëª¨")
    print("=" * 60)
    print("\nì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤.")
    print("=" * 60 + "\n")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False,
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 1400px !important;
        }
        #chatbot {
            height: 600px;
        }
        """
    )
